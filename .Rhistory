# Date: Last modified July 12, 2021
# Manually set the working directory
###############################
# load required packages
###############################
library(data.table)
library(ggplot2)
library(readxl)
library(GGally)
###############################
# important variables
###############################
shared_data_dir <- "G:/.shortcut-targets-by-id/1P7ITMVB9x01fuYfHW8-uWogw4SpbuvwO/Merck Vaccine Improvement Index Project/Data/"
local_data_dir <- "G:/My Drive/PHI/local_data/"
prepped_data_dir <- "G:/My Drive/PHI/local_data/prepped_data/"
code_dir <- "./"
codebook_directory <- paste0(local_data_dir,"/codebooks/")
visDir <- paste0("G:/My Drive/PHI/visualizations/")
###############################
# output files
###############################
outputFile2a = paste0(prepped_data_dir, "2a_vaccine_trends.RDS")
outputFile2b = paste0(prepped_data_dir, "2b_sdi.RDS")
outputFile3 = paste0(prepped_data_dir, "3a_merged_data.RDS")
outputFile4 = paste0(visDir, "aim1_sample_visualizations.PDF")
###############################
# source shared functions
###############################
source(paste0(code_dir, "functions/", "prep_vax_trend_data.R"))
source(paste0(code_dir, "functions/", "strip_chars.R"), encoding = "UTF-8")
###############################
# set Boolean switches
##############################
# Author: Francisco Rios
# Purpose: Prep Vaccination coverage data for analyses
# Date: Last modified July 13, 2021
####### read in vaccine trend data
# Read in list of files to prep
file_list <- data.table(read_excel(paste0(local_data_dir, "data_file_list.xlsx")))
# subset files to vaccine trends
file_list <- file_list[data_type=="vaccination_trends"]
for(i in 1:nrow(file_list)){
# Set up file path
file_dir = paste0(local_data_dir, '/',file_list$data_type[i], '/', file_list$data_source[i], '/' )
# set up arguments
args <- list(file_dir, file_list$file_name[i], file_list$sheet[i], file_list$data_type[i])
### RUN THE PREP FUNCTION HERE ###
tmpData = do.call(prep_vax_trend_data, args)
#Add indexing data
append_cols = file_list[i, .(file_name, data_type, data_source, disease)]
stopifnot(nrow(append_cols)==1)
tmpData = cbind(tmpData, append_cols)
#Bind data together
if(i==1){
prepped_vax_data = tmpData
} else {
prepped_vax_data = rbind(prepped_vax_data, tmpData, use.names=TRUE, fill = TRUE)
}
print(paste0(i, " ", file_list$data_type[i], " ", file_list$disease[i], " ", file_list$file_name[i])) ## if the code breaks, you know which file it broke on
}
# formatting of data
#--if necessary--
View(prepped_vax_data)
# save prepped data
saveRDS(prepped_vax_data, outputFile2a)
# Read in the previously saved files for vaccination trends
vax_dt <- readRDS(outputFile2a)
# read in the previously saved files for sdi
sdi_dt <- readRDS(outputFile2b) # this datatable contains all of the data
vax_concat <- paste0(vax_dt$location_name)
sdi_concat <- paste0(sdi_dt$location_name)
unmapped_loc <- sdi_dt[!vax_concat%in%sdi_concat]
unmapped_loc <- sdi_dt[!sdi_concat%in%vax_concat]
if(nrow(unmapped_mods)>0){
print(unique(unmapped_mods[, c("location_name"), with= FALSE]))
print(unique(unmapped_mods$fileName)) #For documentation in the comments above.
stop("You have unmapped original location names!")
}
# make sure that the merge variables align in both data tables
vax_concat <- paste0(vax_dt$location_name)
sdi_concat <- paste0(sdi_dt$location_name)
unmapped_loc <- sdi_dt[!sdi_concat%in%vax_concat]
if(nrow(unmapped_loc)>0){
print(unique(unmapped_loc[, c("location_name"), with= FALSE]))
print(unique(unmapped_loc$fileName)) #For documentation in the comments above.
stop("You have unmapped original location names!")
}
if(nrow(unmapped_loc)>0){
print(unique(unmapped_loc[, c("location_name"), with= FALSE]))
print(unique(unmapped_loc$file_name)) #For documentation in the comments above.
stop("You have location names in the sdi data that aren't in the vaccine data!")
}
names(unmapped_loc)
# make sure that the merge variables align in both data tables
vax_concat <- paste0(vax_dt$location_name)
sdi_concat <- paste0(sdi_dt$location_name)
unmapped_loc <- vax_concat[!sdi_concat%in%vax_concat]
if(nrow(unmapped_loc)>0){
print(unique(unmapped_loc[, c("location_name"), with= FALSE]))
print(unique(unmapped_loc$file_name)) #For documentation in the comments above.
stop("You have location names in the sdi data that aren't in the vaccine data!")
}
unmapped_loc <- vax_concat[!sdi_concat%in%vax_concat]
nrow(unmapped_loc)
unmapped_loc
# make sure that the merge variables align in both data tables
sdi_concat <- paste0(sdi_dt$location_name)
vax_concat <- paste0(vax_dt$location_name)
unmapped_loc <- vax_concat[!vax_concat%in%sdi_concat]
if(nrow(unmapped_loc)>0){
print(unique(unmapped_loc[, c("location_name"), with= FALSE]))
print(unique(unmapped_loc$file_name)) #For documentation in the comments above.
stop("You have location names in the sdi data that aren't in the vaccine data!")
}
sdi_concat
vax_concat
unmapped_loc
names(unmapped_loc)
unmapped_loc <- vax_dt[!vax_concat%in%sdi_concat]
if(nrow(unmapped_loc)>0){
print(unique(unmapped_loc[, c("location_name"), with= FALSE]))
print(unique(unmapped_loc$file_name)) #For documentation in the comments above.
stop("You have location names in the sdi data that aren't in the vaccine data!")
}
vax_dt[location_name=="Congo"]
sdi_dt[location_name=="Congo"]
rm(list=ls())
# Author: Francisco Rios
# Purpose: Prep socio-demographic data for analyses
# Date: Last modified July 13, 2021
########### To-dos:########
# need to find the loction ID for India (subnational estimates) somewhere
# add check to make sure there are no duplicate rows added or removed
###########################
###################################################
# read in relevant SDI and location data files
###################################################
# SDI data downloaded from GBD
sdi.dat <- as.data.table(read_xlsx(path = paste0(local_data_dir, "sdi/IHME_GBD_2019_SDI_1990_2019_Y2020M10D15.xlsx")))
# read in codebook for locations
loc.codebook <- as.data.table(read_xlsx(path = paste0(codebook_directory, "IHME_GBD_2019_GBD_LOCATION_HIERARCHY_Y2020M10D15.xlsx")))
# locations that need to be added in manually
add.locations <- as.data.table(read_xlsx(path = paste0(codebook_directory, "gbd_location_corrections.xlsx")))
###################################################
# Data Prep
###################################################
# re-name variable names of sdi data
names_sdi <- as.character(sdi.dat[1])
names(sdi.dat) <- names_sdi
sdi.dat <- sdi.dat[-c(1),]
# subset codebook to location ID and Name for matching
loc.cleaning <- loc.codebook[,.(`Location ID`, `Location Name`)]
# rename location name variable in all three data files
setnames(loc.cleaning, old=c("Location Name", "Location ID"), new=c("location", "id"))
setnames(sdi.dat, old=c("Location"), new=c("location"))
setnames(add.locations, old=c("Location ID", "Location Name"), new=c("id", "location"))
# bind rows with country names that are not spelled exactly the same in the codebook
loc.cleaning <- rbind(loc.cleaning, add.locations, fill=TRUE)
# create merge label name in both codebook and data
sdi.dat <- strip_chars(sdi.dat)
loc.cleaning <- strip_chars(loc.cleaning)
# check to make sure that all locations in codebook are in the data
code_check <- paste0(loc.cleaning$location)
data_check <- paste0(sdi.dat$location)
unmapped_codes <- sdi.dat[!data_check%in%code_check]
if(nrow(unmapped_codes)>0){
print(unique(unmapped_codes[, c("location"), with= FALSE]))
# print(unique(unmapped_codes$file_name)) #For documentation in the comments above.
stop("You have locations in the data that aren't in the codebook!")
}
# Author: Francisco Rios
# Purpose: Set up R for prepping UW PHI Vaccination Data
# Date: Last modified July 12, 2021
# Manually set the working directory
###############################
# load required packages
###############################
library(data.table)
library(ggplot2)
library(readxl)
library(GGally)
###############################
# important variables
###############################
shared_data_dir <- "G:/.shortcut-targets-by-id/1P7ITMVB9x01fuYfHW8-uWogw4SpbuvwO/Merck Vaccine Improvement Index Project/Data/"
local_data_dir <- "G:/My Drive/PHI/local_data/"
prepped_data_dir <- "G:/My Drive/PHI/local_data/prepped_data/"
code_dir <- "./"
codebook_directory <- paste0(local_data_dir,"/codebooks/")
visDir <- paste0("G:/My Drive/PHI/visualizations/")
###############################
# output files
###############################
outputFile2a = paste0(prepped_data_dir, "2a_vaccine_trends.RDS")
outputFile2b = paste0(prepped_data_dir, "2b_sdi.RDS")
outputFile3 = paste0(prepped_data_dir, "3a_merged_data.RDS")
outputFile4 = paste0(visDir, "aim1_sample_visualizations.PDF")
###############################
# source shared functions
###############################
source(paste0(code_dir, "functions/", "prep_vax_trend_data.R"))
source(paste0(code_dir, "functions/", "strip_chars.R"), encoding = "UTF-8")
###############################
# set Boolean switches
##############################
# Author: Francisco Rios
# Purpose: Prep socio-demographic data for analyses
# Date: Last modified July 13, 2021
########### To-dos:########
# need to find the loction ID for India (subnational estimates) somewhere
# add check to make sure there are no duplicate rows added or removed
###########################
###################################################
# read in relevant SDI and location data files
###################################################
# SDI data downloaded from GBD
sdi.dat <- as.data.table(read_xlsx(path = paste0(local_data_dir, "sdi/IHME_GBD_2019_SDI_1990_2019_Y2020M10D15.xlsx")))
# read in codebook for locations
loc.codebook <- as.data.table(read_xlsx(path = paste0(codebook_directory, "IHME_GBD_2019_GBD_LOCATION_HIERARCHY_Y2020M10D15.xlsx")))
# locations that need to be added in manually
add.locations <- as.data.table(read_xlsx(path = paste0(codebook_directory, "gbd_location_corrections.xlsx")))
###################################################
# Data Prep
###################################################
# re-name variable names of sdi data
names_sdi <- as.character(sdi.dat[1])
names(sdi.dat) <- names_sdi
sdi.dat <- sdi.dat[-c(1),]
# subset codebook to location ID and Name for matching
loc.cleaning <- loc.codebook[,.(`Location ID`, `Location Name`)]
# rename location name variable in all three data files
setnames(loc.cleaning, old=c("Location Name", "Location ID"), new=c("location", "id"))
setnames(sdi.dat, old=c("Location"), new=c("location"))
setnames(add.locations, old=c("Location ID", "Location Name"), new=c("id", "location"))
# bind rows with country names that are not spelled exactly the same in the codebook
loc.cleaning <- rbind(loc.cleaning, add.locations, fill=TRUE)
# create merge label name in both codebook and data
sdi.dat <- strip_chars(sdi.dat)
loc.cleaning <- strip_chars(loc.cleaning)
# check to make sure that all locations in codebook are in the data
code_check <- paste0(loc.cleaning$location)
data_check <- paste0(sdi.dat$location)
unmapped_codes <- sdi.dat[!data_check%in%code_check]
if(nrow(unmapped_codes)>0){
print(unique(unmapped_codes[, c("location"), with= FALSE]))
# print(unique(unmapped_codes$file_name)) #For documentation in the comments above.
stop("You have locations in the data that aren't in the codebook!")
}
rm(list=ls())
# Author: Francisco Rios
# Purpose: Set up R for prepping UW PHI Vaccination Data
# Date: Last modified July 12, 2021
# Manually set the working directory
###############################
# load required packages
###############################
library(data.table)
library(ggplot2)
library(readxl)
library(GGally)
###############################
# important variables
###############################
shared_data_dir <- "G:/.shortcut-targets-by-id/1P7ITMVB9x01fuYfHW8-uWogw4SpbuvwO/Merck Vaccine Improvement Index Project/Data/"
local_data_dir <- "G:/My Drive/PHI/local_data/"
prepped_data_dir <- "G:/My Drive/PHI/local_data/prepped_data/"
code_dir <- "./"
codebook_directory <- paste0(local_data_dir,"/codebooks/")
visDir <- paste0("G:/My Drive/PHI/visualizations/")
###############################
# output files
###############################
outputFile2a = paste0(prepped_data_dir, "2a_vaccine_trends.RDS")
outputFile2b = paste0(prepped_data_dir, "2b_sdi.RDS")
outputFile3 = paste0(prepped_data_dir, "3a_merged_data.RDS")
outputFile4 = paste0(visDir, "aim1_sample_visualizations.PDF")
###############################
# source shared functions
###############################
source(paste0(code_dir, "functions/", "prep_vax_trend_data.R"))
source(paste0(code_dir, "functions/", "strip_chars.R"), encoding = "UTF-8")
###############################
# set Boolean switches
##############################
# Author: Francisco Rios
# Purpose: Prep Vaccination coverage data for analyses
# Date: Last modified July 13, 2021
####### read in vaccine trend data
# Read in list of files to prep
file_list <- data.table(read_excel(paste0(local_data_dir, "data_file_list.xlsx")))
# subset files to vaccine trends
file_list <- file_list[data_type=="vaccination_trends"]
for(i in 1:nrow(file_list)){
# Set up file path
file_dir = paste0(local_data_dir, '/',file_list$data_type[i], '/', file_list$data_source[i], '/' )
# set up arguments
args <- list(file_dir, file_list$file_name[i], file_list$sheet[i], file_list$data_type[i])
### RUN THE PREP FUNCTION HERE ###
tmpData = do.call(prep_vax_trend_data, args)
#Add indexing data
append_cols = file_list[i, .(file_name, data_type, data_source, disease)]
stopifnot(nrow(append_cols)==1)
tmpData = cbind(tmpData, append_cols)
#Bind data together
if(i==1){
prepped_vax_data = tmpData
} else {
prepped_vax_data = rbind(prepped_vax_data, tmpData, use.names=TRUE, fill = TRUE)
}
print(paste0(i, " ", file_list$data_type[i], " ", file_list$disease[i], " ", file_list$file_name[i])) ## if the code breaks, you know which file it broke on
}
# formatting of data
#--if necessary--
# save prepped data
saveRDS(prepped_vax_data, outputFile2a)
# Author: Francisco Rios
# Purpose: Prep socio-demographic data for analyses
# Date: Last modified July 13, 2021
########### To-dos:########
# need to find the loction ID for India (subnational estimates) somewhere
# add check to make sure there are no duplicate rows added or removed
###########################
###################################################
# read in relevant SDI and location data files
###################################################
# SDI data downloaded from GBD
sdi.dat <- as.data.table(read_xlsx(path = paste0(local_data_dir, "sdi/IHME_GBD_2019_SDI_1990_2019_Y2020M10D15.xlsx")))
# read in codebook for locations
loc.codebook <- as.data.table(read_xlsx(path = paste0(codebook_directory, "IHME_GBD_2019_GBD_LOCATION_HIERARCHY_Y2020M10D15.xlsx")))
# locations that need to be added in manually
add.locations <- as.data.table(read_xlsx(path = paste0(codebook_directory, "gbd_location_corrections.xlsx")))
###################################################
# Data Prep
###################################################
# re-name variable names of sdi data
names_sdi <- as.character(sdi.dat[1])
names(sdi.dat) <- names_sdi
sdi.dat <- sdi.dat[-c(1),]
# subset codebook to location ID and Name for matching
loc.cleaning <- loc.codebook[,.(`Location ID`, `Location Name`)]
# rename location name variable in all three data files
setnames(loc.cleaning, old=c("Location Name", "Location ID"), new=c("location", "id"))
setnames(sdi.dat, old=c("Location"), new=c("location"))
setnames(add.locations, old=c("Location ID", "Location Name"), new=c("id", "location"))
# bind rows with country names that are not spelled exactly the same in the codebook
loc.cleaning <- rbind(loc.cleaning, add.locations, fill=TRUE)
# create merge label name in both codebook and data
sdi.dat <- strip_chars(sdi.dat)
loc.cleaning <- strip_chars(loc.cleaning)
# check to make sure that all locations in codebook are in the data
code_check <- paste0(loc.cleaning$location)
data_check <- paste0(sdi.dat$location)
unmapped_codes <- sdi.dat[!data_check%in%code_check]
if(nrow(unmapped_codes)>0){
print(unique(unmapped_codes[, c("location"), with= FALSE]))
# print(unique(unmapped_codes$file_name)) #For documentation in the comments above.
stop("You have locations in the data that aren't in the codebook!")
}
#############################################
# remove unmapped locations without a location ID for now
#############################################
sdi.dat <- sdi.dat[!location%in%unmapped_codes$location]
# merge the location IDs to the sdi data
sdi.dat <- merge(sdi.dat, loc.cleaning[,.(id, location)], by = "location", all.x = TRUE)
# merge rest of the codebook values to the SDI data
sdi.dat <- merge(sdi.dat, loc.codebook, by.x = "id", by.y = "Location ID", all.x = TRUE)
# check for duplicate rows
print(sdi.dat[duplicated(sdi.dat[,.(location, id)])])
################## manual correction to prepped SDI data due to duplicate names
# manually correct Georgia values (where country and US subnational region are misclassified)
sdi.georgia <- sdi.dat[location=="georgia"]
sdi.georgia <- sdi.georgia[-c(2,3),]
# manually correct Mexico values (where country and Mexico subnational region are misclassified)
sdi.mexico <- sdi.dat[location=="mexico"]
sdi.mexico <- sdi.mexico[-c(2,3),]
# manually correct South Asia values (which is Super-Region and region)
sdi.southasia <- sdi.dat[location=="southasia"]
sdi.southasia <- sdi.southasia[-c(2,3),]
# manually correct North Africa values (which is Super-Region and region)
sdi.northafrica <- sdi.dat[location=="northafricaandmiddleeast"]
sdi.northafrica <- sdi.northafrica[-c(2,3),]
# remove rows that have been cleaned elsewhere
sdi.dat.prepped <- sdi.dat[location != c('georgia') &
location != c('southasia') &
location != c('mexico') &
location !=c('northafricaandmiddleeast')]
# add in rows for newly cleaned data
sdi.dat.prepped <- rbind(sdi.dat.prepped, sdi.georgia, sdi.mexico, sdi.southasia, sdi.northafrica)
# check again for duplicates
print(sdi.dat.prepped[duplicated(sdi.dat.prepped[,.(location, id)])])
# reshape data
sdi.dat.prepped.long = melt(sdi.dat.prepped, id.vars = c("id", "location", "orig_location", "Location Set Version ID",
"Location Name", "Parent ID", "Level", "Sort Order"),
variable.name = "year", value.name = "sdi")
# rename columns in newly prepped data frame
setnames(sdi.dat.prepped.long,
old = c("Location Set Version ID", "Location Name", "Parent ID", "Level", "Sort Order", "id", "year"),
new = c("location_set_version_id", "location_name", "parent_id", "level", "sort_order", "location_id", "year_id" ))
# subset columns
sdi.dat.prepped.long <- sdi.dat.prepped.long[,.(location_name, location_id, location_set_version_id, parent_id, level, sort_order, year_id, sdi)]
# clean numerical values of SDIs
sdi.dat.prepped.long$sdi <- gsub("Â·",".",sdi.dat.prepped.long$sdi)
# convert variable structures
sdi.dat.prepped.long$year_id <- as.numeric(levels(sdi.dat.prepped.long$year_id))[sdi.dat.prepped.long$year_id]
sdi.dat.prepped.long$sdi <- as.numeric(sdi.dat.prepped.long$sdi)
# calculate tertiles from 2019 country-level data
sdi.ter <- sdi.dat.prepped.long[level==3 & year_id==2019]$sdi
quantile(sdi.ter, c(0:3/3))
# classify countries into groups based on SDI
sdi.dat.prepped.long$sdi_group[sdi.dat.prepped.long$sdi <= 0.5826667 ] <- "low"
sdi.dat.prepped.long$sdi_group[sdi.dat.prepped.long$sdi > 0.5826667 & sdi.dat.prepped.long$sdi <= 0.742667 ] <- "medium"
sdi.dat.prepped.long$sdi_group[sdi.dat.prepped.long$sdi > 0.742667 ] <- "high"
# save in prepped data folder
saveRDS(sdi.dat.prepped.long, outputFile2b)
# Read in the previously saved files for vaccination trends
vax_dt <- readRDS(outputFile2a)
# read in the previously saved files for sdi
sdi_dt <- readRDS(outputFile2b) # this datatable contains all of the data
# make sure that the merge variables align in both data tables
sdi_concat <- paste0(sdi_dt$location_name)
vax_concat <- paste0(vax_dt$location_name)
unmapped_loc <- vax_dt[!vax_concat%in%sdi_concat]
if(nrow(unmapped_loc)>0){
print(unique(unmapped_loc[, c("location_name"), with= FALSE]))
print(unique(unmapped_loc$file_name)) #For documentation in the comments above.
stop("You have location names in the vaccine data that aren't in the SDI data!")
}
# merge two data tables sheets together
dt <- merge(vax_dt, sdi_dt, by=c("location_name", "location_id", "year_id"), all.x = TRUE)
# subset from year 1990 to present (as this is extent of SDI data)
dt <- dt[year_id>=1990]
# save location data
saveRDS(dt, outputFile3a)
# save location data
saveRDS(dt, outputFile3)
dt <- readRDS(outputFile3)
# organize groups of variables
varGroups = unique(dt$covariate_name_short)
labelTable <- unique(dt[,.(covariate_name_short, disease)])
g <- 1
l = labelTable[covariate_name_short==varGroups[[g]]]$disease
ggplot(dt[covariate_name_short%in%varGroups[[g]]], aes(y=val, x=year_id, color=covariate_name_short)) +
geom_line() +
facet_wrap(~location_name) +
labs(title=paste('Time series of variables related to', l), y='Value', x='Date',
# subtitle=paste('Random Sample of', n, 'Regions'),
caption='Variables are post-transformation. Transformations may include:
cumulative, log, logit and lag.') +
theme_bw()
n=6
lctns <- sample(dt$location_name, n)
lctns
sample = dt[location_name %in% lctns]
dt <- readRDS(outputFile3)
n=6
lctns <- sample(dt[sdi_group=="low"]$location_name, n)
lctns
sample = dt[location_name %in% lctns]
l
g
# l = nodeTable[variable==lhsVars[g]]$label
ggplot(sample[covariate_name_short%in%varGroups[[g]]], aes(y=val, x=year_id, color=covariate_name_short)) +
geom_line() +
facet_wrap(~location_name) +
labs(title=paste('Time series of variables related to', l), y='Value', x='Date',
# subtitle=paste('Random Sample of', n, 'Regions'),
caption='Variables are post-transformation. Transformations may include:
cumulative, log, logit and lag.') +
theme_bw()
ggplot(sample[covariate_name_short%in%varGroups[[g]]], aes(y=val, x=year_id, color=covariate_name_short)) +
geom_line() +
facet_wrap(~location_name) +
labs(title=paste('Time series of variables related to', l), y='Value', x='Date',
# subtitle=paste('Random Sample of', n, 'Regions'),
caption='Variables are post-transformation. Transformations may include:
cumulative, log, logit and lag.') +
theme_minimal()
ggplot(sample[covariate_name_short%in%varGroups[[g]]], aes(y=val, x=year_id, color=covariate_name_short)) +
geom_line() +
facet_wrap(~location_name) +
labs(title=paste('Time series of vaccine coverage for', l), y='Percent', x='Year',
subtitle=paste('Random Sample of', n, 'locations'), caption='') +
theme_minimal()
ggplot(sample[covariate_name_short%in%varGroups[[g]]], aes(y=val, x=year_id, color=covariate_name_short)) +
geom_line(size = 2, alpha = .8) +
facet_wrap(~location_name) +
labs(title=paste('Time series of vaccine coverage for', l), y='Percent', x='Year',
subtitle=paste('Random Sample of', n, 'locations'), caption='') +
theme_minimal()
ggplot(sample[covariate_name_short%in%varGroups[[g]]], aes(y=val, x=year_id, color=covariate_name_short)) +
geom_line(size = 1, alpha = .8) +
facet_wrap(~location_name) +
labs(title=paste('Time series of vaccine coverage for', l), y='Percent', x='Year',
subtitle=paste('Random Sample of', n, 'locations'), caption='') +
theme_minimal()
tsPlots = lapply(seq(length(varGroups)), function(g) {
l = labelTable[covariate_name_short==varGroups[[g]]]$disease
ggplot(sample[covariate_name_short%in%varGroups[[g]]], aes(y=val, x=year_id, color=covariate_name_short)) +
geom_line(size = 1, alpha = .8) +
facet_wrap(~location_name) +
labs(title=paste('Time series of vaccine coverage for', l), y='Percent', x='Year',
subtitle=paste('Random Sample of', n, 'locations'), caption='') +
theme_minimal()
})
# Save file
print(paste('Saving:', outputFile4))
pdf(outputFile4, height=5.5, width=9)
for(i in seq(length(tsPlots))) {
print(tsPlots[[i]])
}
dev.off()
rm(list=ls())
